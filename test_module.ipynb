{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spatial_Block(nn.Module):\n",
    "    '''\n",
    "    inputsize: Batchsize x Dimension x Length\n",
    "    \n",
    "    input_dimension: \n",
    "    pool_kernel_size: pooling layer size \n",
    "    d_prime: fc convert size\n",
    "    \n",
    "    outputsize: Batchsize x Dimension x Length\n",
    "    '''\n",
    "    def __init__(self, input_dimension, pool_kernel_size, d_prime):\n",
    "        super().__init__()\n",
    "        self.pooling = nn.AvgPool1d(kernel_size=pool_kernel_size, stride=1, padding=(pool_kernel_size-1)//2)\n",
    "        self.fc1 = nn.Linear(in_features=input_dimension, out_features=d_prime)\n",
    "        self.fc2 = nn.Linear(in_features=d_prime, out_features=input_dimension)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.pooling(x)\n",
    "        y = y.transpose(1,2)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y))\n",
    "        y = y.transpose(1,2)\n",
    "        return x * y\n",
    "        \n",
    "class SMATE_Encoder(nn.Module):\n",
    "    '''\n",
    "    input_shape: batch_size x Dimension x Length\n",
    "    output_shape:\n",
    "    \n",
    "    input_dimension: int, the channels/dimension of the input \n",
    "    input_length: int, the length of the input \n",
    "    num_layers: int, the num of blocks \n",
    "    d_prime: List, the hidden size of Spatial block hidden layer, the length of this list should be same as the num_layers\n",
    "    kernels: List, the kernel sizes of each SMATE_Encoder block(both the Convd1d/AvgPooling), the length of this list should be same as the num_layers\n",
    "    out_channels: List, the channels/dimensions of the output of each block,  the length of this list should be same as the num_layers\n",
    "    rnn: Str, optional, default as GRU, the type of RNN in SMATE_Encoder, one of GRU, LSTM\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, input_dimension, input_length, d_prime, kernels, out_channels, final_pool, num_layers=3, rnn=\"GRU\"):\n",
    "        super().__init__()\n",
    "        if rnn is \"GRU\":\n",
    "            self.rnn_sq = nn.GRU(input_size=input_dimension, batch_first=True, hidden_size=out_channels[-1], num_layers=num_layers)\n",
    "        elif rnn is \"LSTM\":\n",
    "            self.rnn_sq = nn.LSTM(input_size=input_dimension, batch_first=True, hidden_size=out_channels[-1], num_layers=num_layers)\n",
    "        out_channels.insert(0, input_dimension)\n",
    "        self.smate = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.smate.add_module(\"smate_block\"+str(i), Spatial_Block(out_channels[i], pool_kernel_size=kernels[i], d_prime=d_prime))\n",
    "            self.smate.add_module(\"conv1d\"+str(i), nn.Conv1d(in_channels=out_channels[i], out_channels=out_channels[i+1], kernel_size=kernels[i], padding=(kernels[i]-1)//2))\n",
    "            self.smate.add_module(\"batch_norm\"+str(i), nn.BatchNorm1d(out_channels[i+1]))\n",
    "            self.smate.add_module(\"relu\"+str(i), nn.ReLU())\n",
    "        self.t_avgpool = nn.AvgPool1d(kernel_size=final_pool, padding=(final_pool-1)//2)\n",
    "        self.s_avgpool = nn.AvgPool1d(kernel_size=final_pool, padding=(final_pool-1)//2)\n",
    "        self.mlp = nn.Sequential()\n",
    "        self.mlp.add_module(\"fc1\", nn.Linear(2*out_channels[-1], out_features=500))\n",
    "        self.mlp.add_module(\"relu\", nn.ReLU())\n",
    "        self.mlp.add_module(\"fc2\", nn.Linear(500, 300))\n",
    "        self.mlp.add_module(\"relu\", nn.ReLU())\n",
    "    def forward(self, x):\n",
    "        x_transpose = x.transpose(1,2)\n",
    "        y_rnn,_ = self.rnn_sq(x_transpose)\n",
    "        y_s = self.smate(x)\n",
    "        y_s = y_s.transpose(1,2)\n",
    "        y = torch.cat([y_s, y_rnn], dim=2)\n",
    "        y = self.mlp(y)\n",
    "        return y\n",
    "    \n",
    "class SMATE_Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, input_dimension, input_length, hidden_size, rnn=\"GRU\"):\n",
    "        '''\n",
    "        input_shape: batch_size X Length X Dimension\n",
    "        ouput_shape: batch_size x Dimension x Length\n",
    "        \n",
    "        input_dimension: int, the channels/dimension of the input \n",
    "        input_length: int, the length of the input \n",
    "        num_layers: int, the num of blocks \n",
    "        d_prime: List, the hidden size of Spatial block hidden layer, the length of this list should be same as the num_layers\n",
    "        kernels: List, the kernel sizes of each SMATE_Encoder block(both the Convd1d/AvgPooling), the length of this list should be same as the num_layers\n",
    "        out_channels: List, the channels/dimensions of the output of each block,  the length of this list should be same as the num_layers\n",
    "        rnn: Str, optional, default as GRU, the type of RNN in SMATE_Encoder, one of GRU, LSTM\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # self.uppool = nn.Upsample()\n",
    "        if rnn is \"GRU\":\n",
    "            self.rnn_sq = nn.GRU(input_size=input_dimension, batch_first=True, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        elif rnn is \"LSTM\":\n",
    "            self.rnn_sq = nn.LSTM(input_size=input_dimension, batch_first=True, hidden_size=hidden_size, num_layers=num_layers) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # y = self.uppool(x)\n",
    "        y,(h,c) = self.rnn_sq(x)\n",
    "        return y\n",
    "def euclidean_dist(x, y):\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "    \n",
    "class ClusterML(nn.Module):\n",
    "    def __init__(self, nclass, input_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.centroid_List = nn.Parameter(torch.zeros([nclass, embedding_size]))\n",
    "        self.flag = [0 for i in range(nclass)]\n",
    "        self.nclass = nclass\n",
    "        self.linear = nn.Linear(input_size ,embedding_size)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        output = self.linear(x)\n",
    "        for i in range(self.nclass):\n",
    "            idx = (y == i)\n",
    "            batch_repr = output[idx].mean(0)\n",
    "            if self.flag[i]:\n",
    "                self.centroid_List[i] += -0.1 * self.centroid_List[i] + 0.1 * batch_repr\n",
    "            else:\n",
    "                self.centroid_List[i] += batch_repr\n",
    "            proto_dist = euclidean_dist(self.centroid_List, self.centroid_List)\n",
    "            proto_dist = torch.exp(-0.5 * proto_dist)\n",
    "            dist = euclidean_dist(output, self.centroid_List)\n",
    "        return F.sigmoid(torch.exp(-0.5 * dist)), proto_dist\n",
    "\n",
    "def output_conv2d_size(in_size, kernel_size, stride=1, padding=0, dilation=1):\n",
    "    output = []\n",
    "    for i in range(2):\n",
    "        output.append((in_size[i]-kernel_size[i]-(dilation-1)*(kernel_size[i]-1)+2*padding)//stride +1)\n",
    "    return output\n",
    "\n",
    "\n",
    "class TDConvdBlock(nn.Module):\n",
    "    def __init__(self, inchannels, outchannels, input_shape, stride, kernel_size=[2,2], use_FAM=True):\n",
    "        super().__init__()\n",
    "        self.out_channels = outchannels\n",
    "        self.outputsize = output_conv2d_size(input_shape, kernel_size,stride=stride)\n",
    "        self.convd = nn.Conv2d(in_channels=inchannels, out_channels=outchannels, stride=stride, kernel_size=kernel_size)\n",
    "        \n",
    "        self.feature_att_fmap = nn.Linear(input_shape[0]*input_shape[1], self.outputsize[0]*self.outputsize[1])\n",
    "        self.feature_att_kernel = nn.Linear(kernel_size[0]*kernel_size[1]*inchannels, self.outputsize[0]*self.outputsize[1])\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x size: batchsize x inchannel x length x width \n",
    "        '''\n",
    "        y = self.convd(x)\n",
    "        kernel_graphs = []\n",
    "        featuremap_graphs = []\n",
    "        N = x.size(0)\n",
    "        \n",
    "        for i in range(self.out_channels):\n",
    "            #kernel_graph size: inchannels x kernel_length x kernel_width \n",
    "            kernel_graph = self.convd.state_dict()['weight'][i]\n",
    "            kernel_graphs.append(torch.unsqueeze(torch.flatten(kernel_graph),dim=0))\n",
    "            #featuremap_graph size: batchsize x inchannels x in_featuremap_length x in_featuremap_width \n",
    "            featuremap_graph = x[:,1,:]\n",
    "            featuremap_graphs.append(torch.unsqueeze(featuremap_graph.view(N, -1),dim=1))\n",
    "        # kernel_graphs cat size: out_channels x kernelshape(eq. length * width)\n",
    "        # attn_kernel size: batchsize x out_channels x kernelshape(eq. length * width)\n",
    "        attn_kernel =  (torch.unsqueeze(torch.cat(kernel_graphs, dim=0),dim=0)).expand(N,-1,-1)\n",
    "        \n",
    "        # featuremap_graphs cat size: batch_size x outchannels x featuremapshape(eq. length * width)\n",
    "        attn_featuremap = torch.cat(featuremap_graphs, dim=1)\n",
    "        # attn_score size:   \n",
    "        \n",
    "        a1 = self.feature_att_fmap(attn_featuremap)\n",
    "        a2 = self.feature_att_kernel(attn_kernel) \n",
    "        print(a1.shape, a2.shape) \n",
    "        attn_score = torch.tanh(a1+a2)\n",
    "        attn_weight = F.softmax(attn_score, dim=2)\n",
    "        attn_weight = torch.reshape(attn_weight, [self.out_channels, self.outputsize[0], -1])\n",
    "        y = y*attn_weight\n",
    "        return y\n",
    "\n",
    "class LocalAttentionModule(nn.Module):\n",
    "    def __init__(self, ecg_seg_length, height, cw):\n",
    "        super().__init__()\n",
    "        self.ecg_seg_linear = nn.Linear(ecg_seg_length, height)\n",
    "        self.featuremap = nn.Linear(cw, 1)\n",
    "        self.height = height\n",
    "    def forward(self, x, ecg_seg):\n",
    "        '''\n",
    "        input_size : batch_size x channels x width x height\n",
    "        ecg_seg : batch_size x ecg_length\n",
    "        '''\n",
    "        N = x.size(0)\n",
    "        # y size: batch_size x height x (width*channels)\n",
    "        y = torch.transpose(x, 1, 3)\n",
    "        y = torch.reshape(y, [N, self.height, -1])\n",
    "\n",
    "        out = torch.squeeze(self.featuremap(y), -1)\n",
    "        ecg_out = self.ecg_seg_linear(ecg_seg)\n",
    "\n",
    "        attn = torch.tanh(out+ecg_out)\n",
    "        attn_score = F.softmax(attn, dim=1)\n",
    "        attn_score = torch.unsqueeze(torch.unsqueeze(attn_score, 1), 1)\n",
    "        return x * attn_score\n",
    "\n",
    "class TestConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(3, 10, 3)\n",
    "        self.linear = nn.Linear(9,1)\n",
    "        self.linear2 = nn.Linear(180,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        N = x.size(0)\n",
    "        y = self.conv(x)\n",
    "        graphs = []\n",
    "        for i in range(10):\n",
    "            # weight size: out_channels x in_channels x kernel_size\n",
    "            # kernel_graph size: in_channels x kernel_size\n",
    "            kernel_graph = self.conv.state_dict()['weight'][i]\n",
    "            # graph size: total_size\n",
    "            graph = torch.flatten(kernel_graph)\n",
    "            graphs.append(torch.unsqueeze(graph, dim=0))\n",
    "            # torch.cat([graphs, ])\n",
    "         \n",
    "        graphs = torch.cat(graphs, dim=0)    \n",
    "        att = self.linear(graphs)\n",
    "        att_weihght = F.softmax(att,dim=1)\n",
    "        att_weihght = att_weihght.expand_as(y)\n",
    "        z= (y * att_weihght).view(N, -1)\n",
    "\n",
    "        return  self.linear2(z)  \n",
    "\n",
    "def three(num_inputs, num_hiddens):\n",
    "    return (\n",
    "        nn.Parameter(torch.randn(num_inputs, num_hiddens), requires_grad=True),\n",
    "        nn.Parameter(torch.randn(num_hiddens, num_hiddens), requires_grad=True),\n",
    "        nn.Parameter(torch.zeros(num_hiddens), requires_grad=True)\n",
    "    )\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.W_xi, self.W_hi, self.b_i = three(input_size, hidden_size)  # 输入门参数\n",
    "        self.W_xf, self.W_hf, self.b_f = three(input_size, hidden_size)  # 遗忘门参数\n",
    "        self.W_xo, self.W_ho, self.b_o = three(input_size, hidden_size)  # 输出门参数\n",
    "        self.W_xc, self.W_hc, self.b_c = three(input_size, hidden_size)  # 候选记忆单元参数\n",
    "        self.W_hq = nn.Parameter(torch.randn(hidden_size, input_size), requires_grad=True)\n",
    "        self.b_q = nn.Parameter(torch.zeros(input_size), requires_grad=True)\n",
    "        self.hidden_size = hidden_size\n",
    "    def forward(self, inputs):\n",
    "        N = inputs.size(1)\n",
    "        (H, C) = (torch.zeros(N, self.hidden_size), torch.zeros(N, self.hidden_size))\n",
    "        outputs = []\n",
    "        for X in inputs:\n",
    "            I = torch.sigmoid((X @ self.W_xi) + (H @ self.W_hi) + self.b_i)\n",
    "            F = torch.sigmoid((X @ self.W_xf) + (H @ self.W_hf) + self.b_f)\n",
    "            O = torch.sigmoid((X @ self.W_xo) + (H @ self.W_ho) + self.b_o)\n",
    "            C_tilda = torch.tanh((X @ self.W_xc) + (H @ self.W_hc) + self.b_c)\n",
    "            C = F * C + I * C_tilda\n",
    "            H = O * torch.tanh(C)\n",
    "            Y = (H @ self.W_hq) + self.b_q\n",
    "            outputs.append(torch.unsqueeze(Y, dim=0))\n",
    "            \n",
    "        return torch.cat(outputs, dim=0), (H, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(2,3,5)\n",
    "l = nn.Linear(5, 1)\n",
    "\n",
    "attn_score = torch.randn(4,5)\n",
    "attn_score = torch.unsqueeze(torch.unsqueeze(attn_score, 1), 1)\n",
    "lam = LocalAttentionModule(30,6,40)\n",
    "ecg_seg = torch.randn(3,30)\n",
    "featuremap = torch.randn(3, 8, 5, 6)\n",
    "g = lam(featuremap, ecg_seg)\n",
    "print(g.size())\n",
    "attn_score.size()\n",
    "lstm = LSTM(5, 6)\n",
    "k,(_,_) = lstm(a) \n",
    "k.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 216]) torch.Size([10, 6, 216])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6, 9, 24])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdb = TDConvdBlock(3, 6, [20,50],2,[3,3])\n",
    "x = torch.randn(10,3,20,50)\n",
    "tdb(x).shape\n",
    "optimizer_ExpLR = torch.optim.SGD()\n",
    "ExpLR = torch.optim.lr_scheduler.ExponentialLR(optimizer_ExpLR, gamma=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "\n",
    "tc = TestConv()\n",
    "input = torch.randn([5,3,20])\n",
    "print(tc(input).size())\n",
    "label = torch.LongTensor([0, 1,0,0,0])\n",
    "loss = F.cross_entropy(tc(input), label)\n",
    "loss.backward()\n",
    "# o = [torch.randn([10,20,30]), torch.randn(10,20,30), torch.randn(10,20,30)]\n",
    "\n",
    "# cvl = nn.Conv2d(10,20,kernel_size=3)\n",
    "# cvl.state_dict()['weight'].size()\n",
    "# torch.unsqueeze(torch.randn(10),dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "leaf variable has been moved into the graph interior",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_168742/845534905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: leaf variable has been moved into the graph interior"
     ]
    }
   ],
   "source": [
    "clusterx = torch.randn([5,20])\n",
    "clustery = torch.LongTensor([1,0,1,0,1])\n",
    "cml = ClusterML(2, 20, 20)\n",
    "\n",
    "# print(o,pd)\n",
    "cml.train()\n",
    "optimizer = torch.optim.Adam(cml.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "o, pd = cml(clusterx, clustery)\n",
    "loss = F.cross_entropy(o, torch.squeeze(clustery))\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 30, 300])\n",
      "torch.Size([10, 3, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [1., 2.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputx = torch.randn([10,3,30])\n",
    "# spb = Spatial_Block(2,3,4)\n",
    "# print(spb(inputx).size())\n",
    "# avgp1d = nn.AvgPool1d(3,1,padding=1)\n",
    "# print(avgp1d(inputx).size())\n",
    "lstmsq = SMATE_Encoder(input_dimension=3, input_length=30, d_prime=20, out_channels=[128,128,128], kernels=[3,3,3], final_pool=3, num_layers=3, rnn=\"LSTM\")\n",
    "print(lstmsq(inputx).size())\n",
    "ln = nn.Linear(30,25)\n",
    "print(ln(inputx).shape)\n",
    "a1 = torch.randn(10,20)\n",
    "a2 = torch.randn(20,30)\n",
    "c = torch.randn(30)\n",
    "(a1 @ a2+c).size()\n",
    "x1 = torch.Tensor([[0,0],[0,0]])\n",
    "x2 = torch.Tensor([1,2])\n",
    "x1+x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import ResNet\n",
    "str(type(ResNet()).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], 1: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], 2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 3: [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]}\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3,\n",
    "        3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "        2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0]\n",
    "labels = np.array(labels)\n",
    "uni = np.unique(labels)\n",
    "dict = {}\n",
    "for i in uni:\n",
    "        dict[i] = [j for j,x in enumerate(labels) if x==i]\n",
    "print(dict)\n",
    "for i in dict:\n",
    "        print(len(dict[i]))\n",
    "x = torch.Tensor([[[1]],[[2]]])\n",
    "y = torch.randn(2,3,2)\n",
    "z = x.expand_as(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0039, 0.5983, 0.8335])\n",
      "tensor([ 0.3076,  1.9460, -0.5611])\n"
     ]
    }
   ],
   "source": [
    "labeltest = torch.LongTensor([1,1,2,2])\n",
    "labeltest[labeltest==1]\n",
    "x = torch.randn([3,3])\n",
    "torch.unique(labeltest)\n",
    "for i in torch.unique(labeltest):\n",
    "    print(x[i])\n",
    "    \n",
    "class LinearT(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(in_channels, out_channels), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(out_channels), requires_grad=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N = x.size(0)\n",
    "        return (x@self.W)+self.b\n",
    "\n",
    "linear_model = LinearT(2,5)\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.01)\n",
    "for i in range(10):\n",
    "    linear_model.train()\n",
    "    x = torch.randn(10,2)\n",
    "    y = torch.LongTensor([0 for i in range(10)])\n",
    "    loss = F.cross_entropy(linear_model(x), y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import SK_MultiScaleConv1dBlock\n",
    "x = torch.randn(10,32,20)\n",
    "model = SK_MultiScaleConv1dBlock(32,0,3)\n",
    "gap = nn.AdaptiveAvgPool1d(1)\n",
    "gap(model(x)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [01:23<1:08:20, 83.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 acc_val:0.8952 time: 4.0783s total_time: 1.3948min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [03:01<43:38, 55.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 acc_val:0.8952 time: 3.5035s total_time: 3.0313min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [04:15<33:33, 44.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 acc_val:0.8952 time: 3.4129s total_time: 4.2665min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [05:26<28:21, 39.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 acc_val:0.8952 time: 3.5099s total_time: 5.4362min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [06:26<23:37, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0009 acc_val:0.8952 time: 3.4311s total_time: 6.4424min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [07:26<20:55, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0011 acc_val:0.8952 time: 3.4147s total_time: 7.4500min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [08:28<19:19, 31.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0013 acc_val:0.8952 time: 3.3978s total_time: 8.4746min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [09:29<18:03, 30.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0015 acc_val:0.8952 time: 3.4536s total_time: 9.4960min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [10:29<16:45, 30.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0017 acc_val:0.8952 time: 3.4157s total_time: 10.4905min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [11:28<15:30, 30.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0019 acc_val:0.8949 time: 3.4626s total_time: 11.4762min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [12:31<14:50, 30.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0021 acc_val:0.8952 time: 3.4001s total_time: 12.5333min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [13:33<13:54, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0023 acc_val:0.8952 time: 3.4076s total_time: 13.5627min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [14:35<12:52, 30.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0025 acc_val:0.8952 time: 3.6238s total_time: 14.5937min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [15:33<11:27, 29.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0027 acc_val:0.8952 time: 3.4172s total_time: 15.5588min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [16:31<10:19, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0029 acc_val:0.8952 time: 3.5317s total_time: 16.5266min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [17:28<09:11, 29.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0031 acc_val:0.8952 time: 3.5114s total_time: 17.4804min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [18:28<08:18, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0033 acc_val:0.8952 time: 3.4338s total_time: 18.4671min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [19:26<07:19, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0035 acc_val:0.8952 time: 3.4599s total_time: 19.4438min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [20:23<06:16, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0037 acc_val:0.8952 time: 3.4575s total_time: 20.3982min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [21:21<05:17, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0039 acc_val:0.8952 time: 3.4425s total_time: 21.3543min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [22:19<04:19, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0041 acc_val:0.8952 time: 3.4690s total_time: 22.3203min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [23:17<03:22, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0043 acc_val:0.8952 time: 3.5501s total_time: 23.2874min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [24:14<02:23, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0045 acc_val:0.8952 time: 3.5160s total_time: 24.2383min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [25:11<01:25, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0047 acc_val:0.8952 time: 3.3967s total_time: 25.1840min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [26:08<00:28, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0049 acc_val:0.8952 time: 3.4235s total_time: 26.1360min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [26:36<00:00, 31.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "from turtle import forward\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from models import * \n",
    "from utils.utils import * \n",
    "from utils.data_loader import mitdb_aryth_batchiter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "seed = 1000\n",
    "random_seed(seed)\n",
    "dataset_divide = [0.6, 0.2, 0.2]\n",
    "\n",
    "class SKnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.skseq = nn.Sequential(\n",
    "            nn.Conv1d(2, 32, 3, padding=1),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.linear = nn.Linear(32, 5)\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        y = self.skseq(x)\n",
    "        y = y.squeeze(2)\n",
    "        return self.linear(y)\n",
    "\n",
    "\n",
    "DS1 = [101, 106, 108, 109, 112, 114, 115, 116, 118, 119,\n",
    "122, 124, 201, 203, 205, 207, 208, 209, 215, 220, 223, 230]\n",
    "DS2 = [100, 103, 105, 111, 113, 117, 121, 123, 200, 202,\n",
    "210, 212, 213, 214, 219, 221, 222, 228, 231, 232, 233, 234]\n",
    "Total_DS = DS1 + DS2\n",
    "random.shuffle(Total_DS)\n",
    "DS_train = Total_DS[0:int(dataset_divide[0] * len(Total_DS))]\n",
    "DS_eval = Total_DS[int(dataset_divide[0] * len(Total_DS)):int((dataset_divide[1] + dataset_divide[0]) * len(Total_DS))]\n",
    "DS_test = Total_DS[int((dataset_divide[1] + dataset_divide[0]) * len(Total_DS)):]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path  = \"../data/mit-bih-arrhythmia-database-1.0.0\"\n",
    "model = ResNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "def train(epochs):\n",
    "    loss_list=[sys.maxsize]\n",
    "    ttime = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_batch_iter = mitdb_aryth_batchiter(10, DS_train, path, use_last_batch=False)\n",
    "        epoch_time = time.time()\n",
    "        \n",
    "\n",
    "        model.train()\n",
    "        loss_total = []\n",
    "        for inputs, labels in train_batch_iter:\n",
    "            t = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_total.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        eval_output = []\n",
    "        eval_label = []\n",
    "        eval_batch_iter = mitdb_aryth_batchiter(10, DS_eval, path)\n",
    "        for inputs, labels in eval_batch_iter:\n",
    "            output = model(inputs)\n",
    "            eval_output.append(output)\n",
    "            eval_label.append(labels)\n",
    "\n",
    "        # eval_pred = torch.cat(eval_output, dim=0)\n",
    "        # eval_pred = eval_pred.max(1)[1].cpu().numpy()\n",
    "\n",
    "        acc_val = accuracy(torch.cat(eval_output,dim=0), torch.cat(eval_label, dim=0))\n",
    "        if epoch%2==0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "            'acc_val:{:.4f}'.format(acc_val),\n",
    "            'time: {:.4f}s'.format(time.time() - epoch_time),\n",
    "            'total_time: {:.4f}min'.format((time.time()-ttime)/60)\n",
    "             )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train(50)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./\"+str(type(model).__name__)+ str(50)\n",
    "mkdir(save_dir)\n",
    "torch.save(model, save_dir+'/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995113608600049\n",
      "[[12273     0     0]\n",
      " [    1     0     0]\n",
      " [    5     0     0]]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    test_output = []\n",
    "    test_label = []\n",
    "    test_batch_iter = mitdb_aryth_batchiter(10, DS_test, path)\n",
    "    for inputs, labels in test_batch_iter:\n",
    "            output = model(inputs)\n",
    "            test_output.append(output)\n",
    "            test_label.append(labels)\n",
    "    acc_val = accuracy(torch.cat(test_output,dim=0), torch.cat(test_label, dim=0))\n",
    "    labels = torch.cat(test_label,dim=0).cpu().numpy()\n",
    "    pred = torch.cat(test_output,dim=0).max(1)[1].cpu().numpy()\n",
    "    print(acc_val)\n",
    "    print(confusion_matrix(labels, pred))\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reversal no longer matters: attention-based arrhythmia detection with lead-reversal ecg data'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改变字体\n",
    "str = \"REVERSAL NO LONGER MATTERS: ATTENTION-BASED ARRHYTHMIA DETECTION WITH LEAD-REVERSAL ECG DATA\"\n",
    "str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 00d00h00m59.4s\n"
     ]
    }
   ],
   "source": [
    "def second2time(second):\n",
    "    intsecond = int(second)\n",
    "    day = int(second) // (24 * 60 * 60)\n",
    "    intsecond -= day * (24 * 60 * 60)\n",
    "    hour = intsecond // (60 * 60)\n",
    "    intsecond -= hour * (60 * 60)\n",
    "    minute = intsecond // 60\n",
    "    intsecond -= 60 * minute\n",
    "    return (day, hour, minute, second - int(second) + intsecond)\n",
    "        \n",
    "day,hour,minute,second = second2time(59.4)\n",
    "\n",
    "print(\"time: {:02d}d{:02d}h{:02d}m{:.1f}s\".format(day, hour, minute, second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = torch.randn(10,3,4)\n",
    "b2 = torch.randn(10,4,5)\n",
    "c = torch.bmm(b1, b2)\n",
    "c.size()\n",
    "zero_mask = torch.triu(torch.ones(5,5), diagonal=0)\n",
    "zero_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.600\n"
     ]
    }
   ],
   "source": [
    "print(\"{:2.3f}\".format(4.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import * \n",
    "class SKnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.skseq = nn.Sequential(\n",
    "            TemporalAttention(258, 2, 8, 8),\n",
    "            nn.Conv1d(2, 32, 3, padding=1),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            TemporalAttention(258, 32, 32, 32),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.linear = nn.Linear(32, 5)\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        y = self.skseq(x)\n",
    "        y = y.squeeze(2)\n",
    "        return self.linear(y)\n",
    "\n",
    "model = SKnet()\n",
    "save_dir = \"./{}{}\".format(str(type(model).__name__), str(50))\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'SKnet' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'SKnet' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8539b3c6e60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_buffer_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'r'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_buffer_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 'r' or 'w' in mode but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_buffer_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0m_check_seekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mraise_err_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seek\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mraise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    300\u001b[0m                                 \u001b[0;34m+\u001b[0m \u001b[0;34m\" Please pre-load the data into a buffer like io.BytesIO and\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                                 + \" try to load from it instead.\")\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'SKnet' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "torch.load(model, save_dir + \"/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'formt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5339c6fb1d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./{}{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'formt'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "from turtle import forward\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from models import * \n",
    "from utils.utils import * \n",
    "from utils.data_loader import mitdb_aryth_batchiter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os \n",
    "\n",
    "sys.stdout = Logger('log.log')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "seed = 503\n",
    "random_seed(seed)\n",
    "dataset_divide = [0.6, 0.2, 0.2]\n",
    "\n",
    "class SKnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.skseq = nn.Sequential(\n",
    "            TemporalAttention(258, 2, 8, 8),\n",
    "            nn.Conv1d(2, 32, 3, padding=1),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            TemporalAttention(258, 32, 32, 32),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.ReLU(),\n",
    "            SK_MultiScaleConv1dBlock(32, 0.8),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.linear = nn.Linear(32, 5)\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        y = self.skseq(x)\n",
    "        y = y.squeeze(2)\n",
    "        return self.linear(y)\n",
    "\n",
    "\n",
    "DS1 = [101, 106, 108, 109, 112, 114, 115, 116, 118, 119,\n",
    "122, 124, 201, 203, 205, 207, 208, 209, 215, 220, 223, 230]\n",
    "DS2 = [100, 103, 105, 111, 113, 117, 121, 123, 200, 202,\n",
    "210, 212, 213, 214, 219, 221, 222, 228, 231, 232, 233, 234]\n",
    "Total_DS = DS1 + DS2\n",
    "random.shuffle(Total_DS)\n",
    "DS_train = Total_DS[0:int(dataset_divide[0] * len(Total_DS))]\n",
    "DS_eval = Total_DS[int(dataset_divide[0] * len(Total_DS)):int((dataset_divide[1] + dataset_divide[0]) * len(Total_DS))]\n",
    "DS_test = Total_DS[int((dataset_divide[1] + dataset_divide[0]) * len(Total_DS)):]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path  = \"../data/mit-bih-arrhythmia-database-1.0.0\"\n",
    "model = ResNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "\n",
    "model = model.cuda()\n",
    "def train(epochs, use_gpu=True):\n",
    "    loss_list=[sys.maxsize]\n",
    "    ttime = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_time = time.time()\n",
    "        train_batch_iter = mitdb_aryth_batchiter(10, DS_train, path, use_last_batch=False)\n",
    "        \n",
    "        \n",
    "\n",
    "        model.train()\n",
    "        loss_total = []\n",
    "        for inputs, labels in train_batch_iter:\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_total.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        eval_output = []\n",
    "        eval_label = []\n",
    "        eval_batch_iter = mitdb_aryth_batchiter(10, DS_eval, path)\n",
    "        for inputs, labels in eval_batch_iter:\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            output = model(inputs)\n",
    "            eval_output.append(output)\n",
    "            eval_label.append(labels)\n",
    "\n",
    "        # eval_pred = torch.cat(eval_output, dim=0)\n",
    "        # eval_pred = eval_pred.max(1)[1].cpu().numpy()\n",
    "\n",
    "        acc_val = accuracy(torch.cat(eval_output,dim=0), torch.cat(eval_label, dim=0))\n",
    "        total_time = time.time() - ttime\n",
    "        day, hour, minute, second = second2time(total_time)\n",
    "        if epoch%2==0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "            'acc_val:{:.4f}'.format(acc_val),\n",
    "            'epoch_time: {:.2f}s'.format(time.time() - epoch_time),\n",
    "            'total_time: {:02d}d{:02d}h{:02d}m{:.1f}s'.format(day, hour, minute, second)\n",
    "             )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train(50)\n",
    "save_dir = \"./{}{}\".format(str(type(model).__name__), str(50))\n",
    "mkdir(save_dir)\n",
    "torch.save(model, save_dir + '/' + 'model.pth')\n",
    "\n",
    "\n",
    "def test(use_gpu=True):\n",
    "    model.eval()\n",
    "    test_output = []\n",
    "    test_label = []\n",
    "    test_batch_iter = mitdb_aryth_batchiter(10, DS_test, path)\n",
    "    for inputs, labels in test_batch_iter:\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        test_output.append(output)\n",
    "        test_label.append(labels)\n",
    "    acc_val = accuracy(torch.cat(test_output,dim=0), torch.cat(test_label, dim=0))\n",
    "    labels = torch.cat(test_label,dim=0).cpu().numpy()\n",
    "    pred = torch.cat(test_output,dim=0).max(1)[1].cpu().numpy()\n",
    "    print(acc_val)\n",
    "    print(confusion_matrix(labels, pred))\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------#\n",
    "\n",
    "#   该函数用于triplet loss,将\n",
    "\n",
    "#-----------------------------------------------------------#\n",
    "def triplet_loss(embeddings, nclass):\n",
    "    \"\"\"Choose the hard positive and negative samples to generate the triplet 选取难正样本和负样本,用于生成triplet_loss\n",
    "\n",
    "    This function is delighted by the paper 'FaceNet: A Unified Embedding for Face Recognition and Clustering' to find the proper triplets in a batch. Hence, the batch should contain the different class samples. The input is the number of class mul the number of samples contained in each class. 这个函数受启发于论文'FaceNet: A Unified Embedding for Face Recognition and Clustering',用于寻找一个batch中的不同triplets.因此输入的每一个batch应该包含每一个种类的样本,输入大小等同于种类数*每个种类包含的样本数.\n",
    "\n",
    "    Args:\n",
    "      embeddings:\n",
    "        the embeddings, which size is batch_size x samples   \n",
    "      \n",
    "    Returns:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    batch_size = embeddings[0]\n",
    "    x = embeddings.unsqueeze(0).expand(embeddings.size(0), embeddings.size(0), embeddings.size(1))\n",
    "    y = embeddings.unsqueeze(1).expand(embeddings.size(0), embeddings.size(0), embeddings.size(1))\n",
    "\n",
    "    distance_metric = torch.pow(x - y, 2).sum(2)\n",
    "    return distance_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 1],\n",
       "        [3, 0, 4],\n",
       "        [1, 4, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = torch.LongTensor([[1,0,0,0],[0,1,0,1],[1,0,1,0]]) \n",
    "a.size()\n",
    "b = a.unsqueeze(1).expand(a.size(0), a.size(0), a.size(1))\n",
    "c = a.unsqueeze(0).expand(a.size(0), a.size(0), a.size(1))\n",
    "torch.pow(b - c, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([0,2,1,0,1,0])\n",
    "c = [j for j,x in enumerate(labels) if x==1]\n",
    "np.max(np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92453d767d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "a = [12][sys.maxsize//12]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
